{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comp_nb_vidhya.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyieWssMosGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab11091-5e9f-44eb-d3f1-0ecce69cec9e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHp-CFEpozSt"
      },
      "source": [
        "#modules\n",
        "#import libraries\n",
        "# Familiar imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For ordinal encoding categorical variables, splitting data\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# For training random forest model\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Data visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "\n",
        "# Configure visualisations\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\n",
        "\n",
        "# Data preprocessing :\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, scale, LabelEncoder, OneHotEncoder\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from xgboost import XGBRegressor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAEIg6-no6u_"
      },
      "source": [
        "#import the dataset\n",
        "train =pd.read_csv('/content/drive/MyDrive/analytics_comp/TRAIN (1).csv')\n",
        "test =pd.read_csv('/content/drive/MyDrive/analytics_comp/TEST_FINAL.csv')\n",
        "sample_submission =pd.read_csv('/content/drive/MyDrive/analytics_comp/SAMPLE.csv')\n",
        "\n",
        "#lengths 188340 22265"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USot2OPCo6tO"
      },
      "source": [
        "#feature engineering\n",
        "\n",
        "df = train.copy()\n",
        "df_test = test.copy()\n",
        "#extract week day out of date\n",
        "df['Day']=df['Date'].apply(lambda x :pd.to_datetime(x,format = '%Y-%m-%d').dayofweek )\n",
        "df_test['Day']= df_test['Date'].apply(lambda x :pd.to_datetime(x,format = '%Y-%m-%d').dayofweek )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzvsjpEoo6qJ"
      },
      "source": [
        "#target encoding for Store_id\n",
        "col ='Store_id'\n",
        "feat = train.groupby(col)[\"Sales\"].agg(\"mean\")\n",
        "df['tar_enc_Store_id']= df[col].map(feat)\n",
        "df_test['tar_enc_Store_id']=df_test[col].map(feat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYmSqu7HSFHR"
      },
      "source": [
        "#kfolds\n",
        "from sklearn import model_selection\n",
        "kf = model_selection.KFold(n_splits=5,shuffle=True,random_state=42)\n",
        "df['kfold']=-1\n",
        "for fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df)):\n",
        "    df.loc[valid_indicies, \"kfold\"] = fold\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSqOxhkao6oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e36550-bad8-409d-be1d-214b920c1d2d"
      },
      "source": [
        "useful_features=['Store_Type', 'Location_Type', 'Region_Code', 'Holiday',\n",
        "       'Discount','Day']\n",
        "ord_cols=[ 'Region_Code','Discount'] \n",
        "one_hot =['Store_Type', 'Location_Type']\n",
        "predictions=[]\n",
        "for fold in range(5):\n",
        "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
        "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    xtest =  df_test.copy()\n",
        "\n",
        "    ytrain = xtrain.Sales\n",
        "    yvalid = xvalid.Sales\n",
        "    \n",
        "    xtrain = xtrain[useful_features]\n",
        "    xvalid = xvalid[useful_features]\n",
        "    xtest  = xtest[useful_features]\n",
        "\n",
        "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
        "    xtrain[ord_cols] = ordinal_encoder.fit_transform(xtrain[ord_cols])\n",
        "    xvalid[ord_cols] = ordinal_encoder.transform(xvalid[ord_cols])\n",
        "    xtest[ord_cols] = ordinal_encoder.transform(xtest[ord_cols])\n",
        "\n",
        "    #onehot cols\n",
        "    # Apply one-hot encoder to each column with categorical data\n",
        "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(xtrain[one_hot]))\n",
        "    OH_cols_valid = pd.DataFrame(OH_encoder.transform(xvalid[one_hot]))\n",
        "    OH_cols_test  = pd.DataFrame(OH_encoder.transform(xtest[one_hot]))\n",
        "\n",
        "    # One-hot encoding removed index; put it back\n",
        "    OH_cols_train.index = xtrain.index\n",
        "    OH_cols_valid.index = xvalid.index\n",
        "\n",
        "    # Remove categorical columns (will replace with one-hot encoding)\n",
        "    num_X_train = xtrain.drop(one_hot, axis=1)\n",
        "    num_X_valid = xvalid.drop(one_hot, axis=1)\n",
        "    num_X_test  = xtest.drop(one_hot,axis=1)\n",
        "\n",
        "    # Add one-hot encoded columns to numerical features\n",
        "    xtrain = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "    xvalid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
        "    xtest  = pd.concat([num_X_test, OH_cols_test],   axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(random_state=1,n_estimators=1000)\n",
        "    # Train the model (will take about 10 minutes to run)\n",
        "    model.fit(xtrain,ytrain)\n",
        "    preds_valid = model.predict(xvalid)\n",
        "    predictions.append(model.predict(xtest)) # Splits\n",
        "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "    print(fold, rmse)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 11410.708892789644\n",
            "1 11480.509288378862\n",
            "2 11409.15982118347\n",
            "3 11377.441516119608\n",
            "4 11372.305882842757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBidM44WpBPM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1liXxkxmAtK"
      },
      "source": [
        "model = RandomForestRegressor(random_state=1,n_estimators=1000)\n",
        "def complete(df,df_test,model):\n",
        "  useful_features=['Store_Type', 'Location_Type', 'Region_Code', 'Holiday',\n",
        "        'Discount','d']\n",
        "  ord_cols=[ 'Region_Code','Discount'] \n",
        "  one_hot =['Store_Type', 'Location_Type']\n",
        "  predictions=[]\n",
        "  xtrain =  df.copy()\n",
        "  xtest =  df_test.copy()\n",
        "  xtrain['d'] = xtrain['Date'].apply(lambda x :pd.to_datetime(x,format = '%Y-%m-%d').day) \n",
        "  xtest['d']  = xtest['Date'].apply(lambda x :pd.to_datetime(x,format = '%Y-%m-%d').day)\n",
        "\n",
        "  ytrain = xtrain.Sales\n",
        "\n",
        "  xtrain = xtrain[useful_features]\n",
        "  xtest  = xtest[useful_features]\n",
        "\n",
        "  ordinal_encoder = preprocessing.OrdinalEncoder()\n",
        "  xtrain[ord_cols] = ordinal_encoder.fit_transform(xtrain[ord_cols])\n",
        "  xtest[ord_cols] = ordinal_encoder.transform(xtest[ord_cols])\n",
        "\n",
        "  #onehot cols\n",
        "  # Apply one-hot encoder to each column with categorical data\n",
        "  OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "  OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(xtrain[one_hot]))\n",
        "  OH_cols_test  = pd.DataFrame(OH_encoder.transform(xtest[one_hot]))\n",
        "\n",
        "  # One-hot encoding removed index; put it back\n",
        "  OH_cols_train.index = xtrain.index\n",
        "\n",
        "  # Remove categorical columns (will replace with one-hot encoding)\n",
        "  num_X_train = xtrain.drop(one_hot, axis=1)\n",
        "  num_X_test  = xtest.drop(one_hot,axis=1)\n",
        "\n",
        "  # Add one-hot encoded columns to numerical features\n",
        "  xtrain = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "  xtest  = pd.concat([num_X_test, OH_cols_test],   axis=1)\n",
        "\n",
        "  # Train the model (will take about 10 minutes to run)\n",
        "  model.fit(xtrain,ytrain)\n",
        "  preds_train = model.predict(xtrain)\n",
        "  rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "  predictions.append(model.predict(xtest)) # Splits\n",
        "  #rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
        "  #print(fold, rmse)\n",
        "  return rmse,predictions[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoe1Qrt-j5Gy",
        "outputId": "8522cc57-507a-455d-d393-049f492b6190"
      },
      "source": [
        "xgb_params = {\n",
        "'lambda': 67.79737006663706,\n",
        "'alpha': 40.12405005448161,\n",
        "'colsample_bytree': 0.061613774851329205,\n",
        "'subsample': 0.9556736521337416,\n",
        "'learning_rate': 0.17024722721525629,\n",
        "'n_estimators': 9489,\n",
        "'max_depth':3,\n",
        "'booster': 'gbtree',\n",
        "'min_child_weight': 155,\n",
        "'seed' : 38,\n",
        "    #'tree_method':'gpu_hist'\n",
        "}\n",
        "model= XGBRegressor()\n",
        "rmse,result = complete(df,df_test,model)\n",
        "print(rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:45:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "11372.305882842757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orQnhBrco6ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5383ce4-680f-4b76-ecc1-528e0fd6c838"
      },
      "source": [
        "len(submission)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22265"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97d7KZFKqwxY",
        "outputId": "26760497-a5be-4a78-ba24-56e60dabf469"
      },
      "source": [
        "result[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([62596.63 , 39418.01 , 63503.367, 38271.723, 38793.   , 63503.367,\n",
              "       62596.63 , 48801.574, 53448.86 , 33482.79 , 53688.406, 38793.   ,\n",
              "       38511.273, 43158.547, 44065.285, 34855.168, 49322.848, 23826.459,\n",
              "       39418.01 , 54595.145], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpS3SYOYoPD1"
      },
      "source": [
        "sample_submission.Sales = submission\n",
        "sample_submission.to_csv(\"submission9.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAjunoVBb2Ue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d13a689d-580b-48bd-c2a1-b84c75213c35"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Store_id</th>\n",
              "      <th>Store_Type</th>\n",
              "      <th>Location_Type</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Date</th>\n",
              "      <th>Holiday</th>\n",
              "      <th>Discount</th>\n",
              "      <th>#Order</th>\n",
              "      <th>Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T1000001</td>\n",
              "      <td>1</td>\n",
              "      <td>S1</td>\n",
              "      <td>L3</td>\n",
              "      <td>R1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9</td>\n",
              "      <td>7011.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T1000002</td>\n",
              "      <td>253</td>\n",
              "      <td>S4</td>\n",
              "      <td>L2</td>\n",
              "      <td>R1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>60</td>\n",
              "      <td>51789.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T1000003</td>\n",
              "      <td>252</td>\n",
              "      <td>S3</td>\n",
              "      <td>L2</td>\n",
              "      <td>R1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>42</td>\n",
              "      <td>36868.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T1000004</td>\n",
              "      <td>251</td>\n",
              "      <td>S2</td>\n",
              "      <td>L3</td>\n",
              "      <td>R1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>23</td>\n",
              "      <td>19715.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T1000005</td>\n",
              "      <td>250</td>\n",
              "      <td>S2</td>\n",
              "      <td>L3</td>\n",
              "      <td>R4</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>62</td>\n",
              "      <td>45614.52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  Store_id Store_Type  ... Discount #Order     Sales\n",
              "0  T1000001         1         S1  ...      Yes      9   7011.84\n",
              "1  T1000002       253         S4  ...      Yes     60  51789.12\n",
              "2  T1000003       252         S3  ...      Yes     42  36868.20\n",
              "3  T1000004       251         S2  ...      Yes     23  19715.16\n",
              "4  T1000005       250         S2  ...      Yes     62  45614.52\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    }
  ]
}